{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP583 - Data Camp\n",
    "# Course project\n",
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen this dataset from Kaggle (https://www.kaggle.com/mlg-ulb/creditcardfraud/data), containing credid card transactions data, and the objective is to predict the transactions which are frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if there is null data\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing 'Time' column and normalizing (scaling) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is necessary, because of the way the SVDD library is coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_svm = labels.copy()\n",
    "labels_svm[labels == 1] = -1 # fraud\n",
    "labels_svm[labels == 0] = 1 # non-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_features = StandardScaler().fit_transform(data.values)\n",
    "scaled_data = pd.DataFrame(scaled_features,\n",
    "                           index=data.index,\n",
    "                           columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.157366e-16</td>\n",
       "      <td>3.154853e-17</td>\n",
       "      <td>-4.409878e-15</td>\n",
       "      <td>-6.734811e-16</td>\n",
       "      <td>-2.874435e-16</td>\n",
       "      <td>4.168992e-16</td>\n",
       "      <td>-8.767997e-16</td>\n",
       "      <td>-2.423604e-16</td>\n",
       "      <td>3.078727e-16</td>\n",
       "      <td>2.026926e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.754870e-16</td>\n",
       "      <td>1.685077e-17</td>\n",
       "      <td>1.478472e-15</td>\n",
       "      <td>-6.797197e-16</td>\n",
       "      <td>1.234659e-16</td>\n",
       "      <td>-7.659279e-16</td>\n",
       "      <td>3.247603e-16</td>\n",
       "      <td>-2.953495e-18</td>\n",
       "      <td>5.401572e-17</td>\n",
       "      <td>3.202236e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>-2.258191e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.069146e+01</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>-4.917360e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.746334e-01</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>-8.533551e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104705e-02</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>4.168842e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725733e-01</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>2.180758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.113464e+01</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -8.157366e-16  3.154853e-17 -4.409878e-15 -6.734811e-16 -2.874435e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00 -8.240810e+01   \n",
       "25%   -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01 -5.010686e-01   \n",
       "50%    9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02 -3.936682e-02   \n",
       "75%    6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01  4.433465e-01   \n",
       "max    1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01  2.521413e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.168992e-16 -8.767997e-16 -2.423604e-16  3.078727e-16  2.026926e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01 -2.258191e+01   \n",
       "25%   -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01 -4.917360e-01   \n",
       "50%   -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02 -8.533551e-02   \n",
       "75%    2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01  4.168842e-01   \n",
       "max    5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01  2.180758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...       2.754870e-16  1.685077e-17  1.478472e-15 -6.797197e-16   \n",
       "std        ...       1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...      -7.069146e+01 -4.741907e+01 -1.506565e+01 -7.175446e+01   \n",
       "25%        ...      -2.746334e-01 -3.109433e-01 -7.473476e-01 -2.591784e-01   \n",
       "50%        ...      -8.104705e-02 -4.009429e-02  9.345377e-03 -1.792420e-02   \n",
       "75%        ...       1.725733e-01  2.537392e-01  7.283360e-01  2.364319e-01   \n",
       "max        ...       5.113464e+01  3.703471e+01  1.447304e+01  3.607668e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.234659e-16 -7.659279e-16  3.247603e-16 -2.953495e-18  5.401572e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.683638e+00 -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01   \n",
       "25%   -5.854676e-01 -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01   \n",
       "50%    6.765678e-02  3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02   \n",
       "75%    7.257153e-01  6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01   \n",
       "max    7.569684e+00  1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02   \n",
       "\n",
       "             Amount  \n",
       "count  2.848070e+05  \n",
       "mean   3.202236e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.532294e-01  \n",
       "25%   -3.308401e-01  \n",
       "50%   -2.652715e-01  \n",
       "75%   -4.471707e-02  \n",
       "max    1.023622e+02  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.drop(['Class'], axis=1, inplace=True)\n",
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    284315\n",
      "-1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEaCAYAAADg2nttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRFgAAAz9P9dw8TAHErhiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1068f9ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = labels_svm.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Plot a histogram\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title(\"Fraud distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency (log)\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 99.827%\n"
     ]
    }
   ],
   "source": [
    "print('Baseline: {:.3f}%'.format(len(labels_svm[labels_svm == 1]) / len(labels_svm) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy is therefore 99.827%, so any model which performs below this threshold isn't doing very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # \"Pareto rule\", 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data,\n",
    "                                                    labels_svm,\n",
    "                                                    test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use only non-fraud points to train SVDD\n",
    "In the library we only have SVDD implemented. There is not an implementation of SVDD-neg (a version that incorporates negative examples also)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBSVM:\n",
    "\n",
    "https://github.com/cjlin1/libsvm\n",
    "\n",
    "https://github.com/cjlin1/libsvm/tree/master/python # bindings em Python\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf # article\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf # guide\n",
    "\n",
    "SVDD:\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#libsvm_for_svdd_and_finding_the_smallest_sphere_containing_all_data\n",
    "\n",
    "One-class SVM:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras pessoas tiveram a mesma pergunta, mas aparentemente ninguém tem o SVDD-neg implementado\n",
    "https://www.reddit.com/r/MachineLearning/comments/396o0n/experience_training_support_vector_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteca em MATLAB (tem a ver com o criador de SVDD)\n",
    "\n",
    "https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/pattern-recognition-bioinformatics/pattern-recognition-laboratory/data-and-software/dd-tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_fraud_X_train = X_train[y_train==1].values.tolist()\n",
    "non_fraud_y_train = y_train[y_train==1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from svm import *\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem = svm_problem(non_fraud_y_train,\n",
    "                      non_fraud_X_train,\n",
    "                      isKernel=False) # set to True if precomputed Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = svm_parameter()\n",
    "param.svm_type = 5\n",
    "param.kernel_type = 3\n",
    "param.degree = 2\n",
    "param.gamma = 0.1\n",
    "param.C = 1\n",
    "param.eps = 0.001\n",
    "param.cross_validation = False\n",
    "param.nr_fold = 0\n",
    "model = svm_train(problem, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.values.tolist()\n",
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't use the negative labels in the training set, I am adding them to our test set (maybe this is wrong to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.extend(y_train[y_train==-1].values.tolist())\n",
    "X_test.extend(X_train[y_train==-1].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.1962% (56892/57353) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99.19620595260928, 0.03215176189562882, 0.0626704172326382)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = np.array(p_val)\n",
    "lab = np.array(p_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = val.reshape(val.shape[0])\n",
    "lab = lab.reshape(lab.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(np.where(lab<0)).flatten() == np.array(np.where(val>0)).flatten()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_label : +1 para não fraude, -1 para fraude\n",
    "\n",
    "p_val : negativo para não fraude, positivo para fraude (não sei nada sobre a magnitude de p_val ainda, mas acredito que seja a distância até a decision boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under the precision-recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDD method doesn't predict probabilities, but the output p_val is the distance of each point to the decision boundary (negative for non-frauds and positive for frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x204df666d8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEaCAYAAADtxAsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e3c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, p_val, pos_label=-1)\n",
    "average_precision = -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.3f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15654949979088312"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space = {'kernel': hp.choice('kernel_type', [\n",
    "                                {'type': LINEAR,},\n",
    "                                {'type': POLY,\n",
    "                                 'gamma': hp.lognormal('linear_gamma', 0, 1),\n",
    "                                 'coef0': hp.normal('linear_coef0', 0, 2),\n",
    "                                 'degree': hp.choice('linear_deg', [2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
    "                                },\n",
    "                                {'type': RBF,\n",
    "                                 'gamma': hp.lognormal('rbf_gamma', 0, 1),\n",
    "                                },\n",
    "                                {'type': SIGMOID,\n",
    "                                 'gamma': hp.lognormal('sig_gamma', 0, 1),\n",
    "                                 'coef0': hp.normal('sig_coef0', 0, 2),\n",
    "                                }\n",
    "                                 ]),\n",
    "         'C': hp.loguniform('svdd_C', -13, 0),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Objective_SVDD(object):\n",
    "    \"\"\"\n",
    "    A class to encapsulate the SVC model and our objective function (the error in this case, to minimize)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.history_f = []\n",
    "        self.fbest = np.inf\n",
    "        self.history_f_best = []\n",
    "        self.problem = svm_problem(non_fraud_y_train,\n",
    "                                   non_fraud_X_train,\n",
    "                                   isKernel=False) # set to True if precomputed Kernel\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def __call__(self, params):\n",
    "        print('New model with parameters: ')\n",
    "        print(params)\n",
    "        param = svm_parameter()\n",
    "        param.svm_type = 5\n",
    "        param.kernel_type = params['kernel']['type']\n",
    "        if params['kernel']['type'] != LINEAR:\n",
    "            \n",
    "            if params['kernel']['type'] == POLY:\n",
    "                param.degree = params['kernel']['degree']\n",
    "            \n",
    "            if params['kernel']['type'] != RBF:\n",
    "                param.coef0 = params['kernel']['coef0']\n",
    "            \n",
    "            param.gamma = params['kernel']['gamma']\n",
    "            \n",
    "        param.C = params['C']\n",
    "        param.eps = 0.001\n",
    "        param.cross_validation = False\n",
    "        param.nr_fold = 0\n",
    "        \n",
    "        print('Training model')\n",
    "        t = time.time()\n",
    "        model = svm_train(self.problem, param)\n",
    "        print('Model trained, train time: {}'.format(time.time() - t))\n",
    "        \n",
    "        print('Predicting using model')\n",
    "        t = time.time()\n",
    "        p_label, p_acc, p_val = svm_predict(y_test, X_test, model)\n",
    "        print('Done predicting, predict time: {}'.format(time.time() - t))\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, p_val, pos_label=-1)\n",
    "        average_precision = -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    "        print('AP: {}'.format(average_precision))\n",
    "        f = 1 - average_precision # error function\n",
    "        \n",
    "        self.history_f.append(f)\n",
    "        if f < self.fbest:\n",
    "            self.fbest = f\n",
    "        self.history_f_best.append(self.fbest)\n",
    "        print('Time elapsed since begginning: {}'.format(time.time() - self.start_time))\n",
    "        \n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model with parameters: \n",
      "{'C': 7.091464242110048e-05, 'kernel': {'gamma': 0.7675641658262338, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 446.9808990955353\n",
      "Accuracy = 51.2842% (29413/57353) (classification)\n",
      "AP: 0.34709645120174465\n",
      "Time elapsed since begginning: 565.9185779094696\n",
      "New model with parameters: \n",
      "{'C': 0.3334342862814778, 'kernel': {'coef0': 1.4369642049754712, 'gamma': 0.4438792751533149, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 0.7406961917877197\n",
      "Accuracy = 99.1404% (56860/57353) (classification)\n",
      "AP: 0.031121597509381024\n",
      "Time elapsed since begginning: 569.0358200073242\n",
      "New model with parameters: \n",
      "{'C': 0.0016435835823549495, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 44.63445997238159\n",
      "Accuracy = 99.2014% (56895/57353) (classification)\n",
      "AP: 0.4579040566579266\n",
      "Time elapsed since begginning: 620.2323226928711\n",
      "New model with parameters: \n",
      "{'C': 0.001961574116934112, 'kernel': {'coef0': -1.621489420845775, 'gamma': 2.67801322393465, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 69.05646896362305\n",
      "Accuracy = 98.9661% (56760/57353) (classification)\n",
      "AP: 0.012883535299835228\n",
      "Time elapsed since begginning: 696.3201558589935\n",
      "New model with parameters: \n",
      "{'C': 0.00018859640039924322, 'kernel': {'gamma': 0.38593575223087767, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 1101.614499092102\n",
      "Accuracy = 53.4009% (30627/57353) (classification)\n",
      "AP: 0.5168979993252728\n",
      "Time elapsed since begginning: 1863.8313715457916\n",
      "New model with parameters: \n",
      "{'C': 0.04416819888706847, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 1.3573009967803955\n",
      "Accuracy = 99.1613% (56872/57353) (classification)\n",
      "AP: 0.49299261800370353\n",
      "Time elapsed since begginning: 1867.626898765564\n",
      "New model with parameters: \n",
      "{'C': 3.3951398669513877e-06, 'kernel': {'coef0': -3.3491769589881852, 'degree': 7, 'gamma': 1.246113251900313, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 2405.20148563385\n",
      "Accuracy = 0.857845% (492/57353) (classification)\n",
      "AP: 0.4208610036761857\n",
      "Time elapsed since begginning: 5710.7948269844055\n",
      "New model with parameters: \n",
      "{'C': 6.325283529810813e-06, 'kernel': {'coef0': 1.9690049850021658, 'gamma': 0.9417836463715797, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 17147.18863582611\n",
      "Accuracy = 31.3358% (17972/57353) (classification)\n",
      "AP: 0.09747593363976309\n",
      "Time elapsed since begginning: 24590.288787841797\n",
      "New model with parameters: \n",
      "{'C': 5.3908104791540686e-05, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 3224.0989079475403\n",
      "Accuracy = 91.9499% (52736/57353) (classification)\n",
      "AP: 0.4279849198787188\n",
      "Time elapsed since begginning: 28320.921942710876\n",
      "New model with parameters: \n",
      "{'C': 0.645143579454145, 'kernel': {'coef0': 0.2405694019014378, 'degree': 4, 'gamma': 0.4531342452254681, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 7.328063011169434\n",
      "Accuracy = 99.1404% (56860/57353) (classification)\n",
      "AP: 0.5098226528685003\n",
      "Time elapsed since begginning: 28331.21138358116\n",
      "New model with parameters: \n",
      "{'C': 0.005858011804702442, 'kernel': {'coef0': -0.9764117804444707, 'degree': 2, 'gamma': 2.0301598403012835, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 23.17287588119507\n",
      "Accuracy = 99.2694% (56934/57353) (classification)\n",
      "AP: 0.35652874416061253\n",
      "Time elapsed since begginning: 28362.774171829224\n",
      "New model with parameters: \n",
      "{'C': 0.0007671518358913374, 'kernel': {'coef0': -0.5193832621146243, 'gamma': 3.7539816734132825, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 318.8019587993622\n",
      "Accuracy = 98.64% (56573/57353) (classification)\n",
      "AP: 0.010460517731065967\n",
      "Time elapsed since begginning: 28704.856076717377\n",
      "New model with parameters: \n",
      "{'C': 0.010466625447002829, 'kernel': {'coef0': 0.9244388946323212, 'degree': 6, 'gamma': 2.00653930310276, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 8.795208930969238\n",
      "Accuracy = 99.3043% (56954/57353) (classification)\n",
      "AP: 0.2040256674943424\n",
      "Time elapsed since begginning: 28717.13381576538\n",
      "New model with parameters: \n",
      "{'C': 0.0010345247514081004, 'kernel': {'coef0': -1.479507600441717, 'degree': 2, 'gamma': 1.2388297902674323, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 789.590393781662\n",
      "Accuracy = 99.0776% (56824/57353) (classification)\n",
      "AP: 0.45384133054642783\n",
      "Time elapsed since begginning: 29521.030188798904\n",
      "New model with parameters: \n",
      "{'C': 0.00028640685479982436, 'kernel': {'coef0': 2.0522610242141215, 'degree': 7, 'gamma': 0.32774504539099447, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 490.9255039691925\n",
      "Accuracy = 98.1291% (56280/57353) (classification)\n",
      "AP: 0.346736710198006\n",
      "Time elapsed since begginning: 30112.570118904114\n",
      "New model with parameters: \n",
      "{'C': 0.06299023330637346, 'kernel': {'coef0': 0.4870454764042913, 'gamma': 2.2008436739316855, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 2.644031047821045\n",
      "Accuracy = 99.1369% (56858/57353) (classification)\n",
      "AP: 0.014188517364107586\n",
      "Time elapsed since begginning: 30118.5399889946\n",
      "New model with parameters: \n",
      "{'C': 1.3160980564248206e-05, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 9913.160310983658\n",
      "Accuracy = 67.0532% (38457/57353) (classification)\n",
      "AP: 0.4152297374903907\n",
      "Time elapsed since begginning: 40976.448306798935\n",
      "New model with parameters: \n",
      "{'C': 0.0014913815748181735, 'kernel': {'gamma': 0.42105551049286966, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 82.19349575042725\n",
      "Accuracy = 1.70349% (977/57353) (classification)\n",
      "AP: 0.4612450461314475\n",
      "Time elapsed since begginning: 41072.32224082947\n",
      "New model with parameters: \n",
      "{'C': 0.03836755257559869, 'kernel': {'gamma': 1.7614349228245911, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 134.75661611557007\n",
      "Accuracy = 0.857845% (492/57353) (classification)\n",
      "AP: 0.0804794195898029\n",
      "Time elapsed since begginning: 41228.59602975845\n",
      "New model with parameters: \n",
      "{'C': 0.0003371225614360008, 'kernel': {'coef0': 0.321426648094381, 'degree': 10, 'gamma': 2.76572762513386, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 499.5563621520996\n",
      "Accuracy = 98.2128% (56328/57353) (classification)\n",
      "AP: 0.2772919447597489\n",
      "Time elapsed since begginning: 41778.647788763046\n",
      "New model with parameters: \n",
      "{'C': 0.6101821089417669, 'kernel': {'gamma': 0.2311751920537767, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 118.36565589904785\n",
      "Accuracy = 0.861332% (494/57353) (classification)\n",
      "AP: 0.46832821877628344\n",
      "Time elapsed since begginning: 41917.79147577286\n",
      "New model with parameters: \n",
      "{'C': 0.00011299055500831937, 'kernel': {'gamma': 0.3793995537888832, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 854.4116699695587\n",
      "Accuracy = 81.7534% (46888/57353) (classification)\n",
      "AP: 0.5329987024755315\n",
      "Time elapsed since begginning: 43060.21702671051\n",
      "New model with parameters: \n",
      "{'C': 4.5332053320054425e-05, 'kernel': {'gamma': 0.03832618946797955, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 11538.252737045288\n",
      "Accuracy = 90.4469% (51874/57353) (classification)\n",
      "AP: 0.55745619601212\n",
      "Time elapsed since begginning: 55020.950514793396\n",
      "New model with parameters: \n",
      "{'C': 2.8333489212566444e-05, 'kernel': {'gamma': 0.014553880873891313, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 4421.731295108795\n",
      "Accuracy = 84.7924% (48631/57353) (classification)\n",
      "AP: 0.4524756975110224\n",
      "Time elapsed since begginning: 59973.916388750076\n",
      "New model with parameters: \n",
      "{'C': 2.6139148908743155e-06, 'kernel': {'gamma': 0.04885924245460519, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3017.234180212021\n",
      "Accuracy = 0.857845% (492/57353) (classification)\n",
      "AP: 0.5249147622340256\n",
      "Time elapsed since begginning: 64552.84478998184\n",
      "New model with parameters: \n",
      "{'C': 0.0001073463709671187, 'kernel': {'gamma': 0.0655684990525661, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3109.5241100788116\n",
      "Accuracy = 96.2966% (55229/57353) (classification)\n",
      "AP: 0.608759177617815\n",
      "Time elapsed since begginning: 67876.60588955879\n",
      "New model with parameters: \n",
      "{'C': 1.749866915849529e-05, 'kernel': {'gamma': 0.039954062685039815, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 6882.215195894241\n",
      "Accuracy = 74.6413% (42809/57353) (classification)\n",
      "AP: 0.5313877889232462\n",
      "Time elapsed since begginning: 75499.92998576164\n",
      "New model with parameters: \n",
      "{'C': 6.637826829916156e-06, 'kernel': {'gamma': 0.04677253794487342, 'type': 2}}\n",
      "Training model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained, train time: 12861.21344423294\n",
      "Accuracy = 34.2615% (19649/57353) (classification)\n",
      "AP: 0.5281802059925425\n",
      "Time elapsed since begginning: 89661.7672958374\n",
      "New model with parameters: \n",
      "{'C': 8.365258763523751e-05, 'kernel': {'gamma': 0.029652012975241584, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 4622.532025814056\n",
      "Accuracy = 94.8599% (54405/57353) (classification)\n",
      "AP: 0.55850931622426\n",
      "Time elapsed since begginning: 94553.33243489265\n",
      "New model with parameters: \n",
      "{'C': 9.913377041288044e-05, 'kernel': {'gamma': 0.02320022658195079, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3130.4436779022217\n",
      "Accuracy = 95.4876% (54765/57353) (classification)\n",
      "AP: 0.54541674629573\n",
      "Time elapsed since begginning: 97917.58446884155\n",
      "New model with parameters: \n",
      "{'C': 0.00550709944166736, 'kernel': {'gamma': 0.08679151479230057, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 264.4364399909973\n",
      "Accuracy = 37.0059% (21224/57353) (classification)\n",
      "AP: 0.5492339260399066\n",
      "Time elapsed since begginning: 98197.90939688683\n",
      "New model with parameters: \n",
      "{'C': 0.0006064972233281289, 'kernel': {'gamma': 12.789862552118475, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 73.81564521789551\n",
      "Accuracy = 1.81856% (1043/57353) (classification)\n",
      "AP: 0.011530704195635247\n",
      "Time elapsed since begginning: 98285.79726481438\n",
      "New model with parameters: \n",
      "{'C': 0.00015395554783287355, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 2650.9834699630737\n",
      "Accuracy = 97.1527% (55720/57353) (classification)\n",
      "AP: 0.447675164985648\n",
      "Time elapsed since begginning: 101056.65984988213\n",
      "New model with parameters: \n",
      "{'C': 1.2187367906877998e-05, 'kernel': {'gamma': 0.09473947083696976, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 9218.920545101166\n",
      "Accuracy = 61.5661% (35310/57353) (classification)\n",
      "AP: 0.5941800609314436\n",
      "Time elapsed since begginning: 111285.0932867527\n",
      "New model with parameters: \n",
      "{'C': 1.1623388986531722e-05, 'kernel': {'coef0': 4.902326706421234, 'gamma': 0.9866532478751547, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 11822.98040819168\n",
      "Accuracy = 62.6977% (35959/57353) (classification)\n",
      "AP: 0.15203718136455607\n",
      "Time elapsed since begginning: 124322.29014492035\n",
      "New model with parameters: \n",
      "{'C': 2.293403779996434e-06, 'kernel': {'gamma': 0.08074699017127543, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3464.2137517929077\n",
      "Accuracy = 0.857845% (492/57353) (classification)\n",
      "AP: 0.5714677823259472\n",
      "Time elapsed since begginning: 129367.38468575478\n",
      "New model with parameters: \n",
      "{'C': 3.184369513268658e-05, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 3266.0435988903046\n",
      "Accuracy = 86.4506% (49582/57353) (classification)\n",
      "AP: 0.42207068743839016\n",
      "Time elapsed since begginning: 133083.45860767365\n",
      "New model with parameters: \n",
      "{'C': 5.931450690620044e-06, 'kernel': {'gamma': 0.0763452376784449, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 13043.014059066772\n",
      "Accuracy = 26.1364% (14990/57353) (classification)\n",
      "AP: 0.572055305341361\n",
      "Time elapsed since begginning: 147488.9709777832\n",
      "New model with parameters: \n",
      "{'C': 0.0003259065888937846, 'kernel': {'coef0': -4.794045311941288, 'gamma': 0.5396506707854577, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 2551.5464372634888\n",
      "Accuracy = 97.8589% (56125/57353) (classification)\n",
      "AP: 0.01844445580545135\n",
      "Time elapsed since begginning: 150086.91720581055\n",
      "New model with parameters: \n",
      "{'C': 0.003980017672933544, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 17.74494218826294\n",
      "Accuracy = 99.245% (56920/57353) (classification)\n",
      "AP: 0.42730565180343283\n",
      "Time elapsed since begginning: 150108.5370028019\n",
      "New model with parameters: \n",
      "{'C': 4.342735589104491e-06, 'kernel': {'gamma': 0.11291474265176056, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3007.8861212730408\n",
      "Accuracy = 0.857845% (492/57353) (classification)\n",
      "AP: 0.5918083612134974\n",
      "Time elapsed since begginning: 154673.03390789032\n",
      "New model with parameters: \n",
      "{'C': 0.0023263702768815614, 'kernel': {'coef0': -1.9118343280295447, 'gamma': 0.21599278943385547, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 61.86426496505737\n",
      "Accuracy = 99.0149% (56788/57353) (classification)\n",
      "AP: 0.01944669614598174\n",
      "Time elapsed since begginning: 154740.98227787018\n",
      "New model with parameters: \n",
      "{'C': 0.015978726212833628, 'kernel': {'gamma': 0.06200508224842481, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 200.4939980506897\n",
      "Accuracy = 14.6322% (8392/57353) (classification)\n",
      "AP: 0.519056742539916\n",
      "Time elapsed since begginning: 154953.08935976028\n",
      "New model with parameters: \n",
      "{'C': 2.171413884766342e-05, 'kernel': {'type': 0}}\n",
      "Training model\n",
      "Model trained, train time: 5084.361468791962\n",
      "Accuracy = 80.1894% (45991/57353) (classification)\n",
      "AP: 0.41875470923614283\n",
      "Time elapsed since begginning: 160597.91640496254\n",
      "New model with parameters: \n",
      "{'C': 0.17926872509900932, 'kernel': {'coef0': 3.2147029827699876, 'degree': 3, 'gamma': 6.128463844845475, 'type': 1}}\n",
      "Training model\n",
      "Model trained, train time: 0.3963460922241211\n",
      "Accuracy = 99.1387% (56859/57353) (classification)\n",
      "AP: 0.36537856257870327\n",
      "Time elapsed since begginning: 160600.66148662567\n",
      "New model with parameters: \n",
      "{'C': 4.7128249802657746e-05, 'kernel': {'gamma': 0.11949802518871225, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 4800.735097169876\n",
      "Accuracy = 92.3334% (52956/57353) (classification)\n",
      "AP: 0.6003255305438325\n",
      "Time elapsed since begginning: 165797.8275346756\n",
      "New model with parameters: \n",
      "{'C': 0.000587890220043623, 'kernel': {'coef0': -0.8288740614562721, 'gamma': 1.3319006474642834, 'type': 3}}\n",
      "Training model\n",
      "Model trained, train time: 455.1586630344391\n",
      "Accuracy = 98.4831% (56483/57353) (classification)\n",
      "AP: 0.010346267312242065\n",
      "Time elapsed since begginning: 166270.72274374962\n",
      "New model with parameters: \n",
      "{'C': 0.00022635955887900683, 'kernel': {'gamma': 0.12583507326547783, 'type': 2}}\n",
      "Training model\n",
      "Model trained, train time: 3164.506247282028\n",
      "Accuracy = 80.5869% (46219/57353) (classification)\n",
      "AP: 0.5822187371456065\n",
      "Time elapsed since begginning: 169523.29268479347\n",
      "New model with parameters: \n",
      "{'C': 4.0623307853558943e-05, 'kernel': {'coef0': -1.1695443357855926, 'degree': 5, 'gamma': 0.13420804147517673, 'type': 1}}\n",
      "Training model\n"
     ]
    }
   ],
   "source": [
    "fun_SVDD = Objective_SVDD()\n",
    "trials = Trials()\n",
    "best = fmin(fun_SVDD, space, algo=tpe.suggest, max_evals = 100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(1 - res_cma[1]))\n",
    "print(\"Optimal parameters: {}\".format(fun_cma.encode(*res_cma[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_params = fun_cma.encode(*res_cma[0])\n",
    "param.C = optimized_params['C']\n",
    "param.gamma = optimized_params['gamma']\n",
    "model = svm_train(problem, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_save_model('./model_1.m', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm_load_model('./model_1.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (average_precision_score,\n",
    "                             accuracy_score,\n",
    "                             classification_report,\n",
    "                             f1_score)\n",
    "average_precision = average_precision_score(y_test, p_val)\n",
    "f1 = f1_score(y_test, p_label)\n",
    "acc = accuracy_score(y_test, p_label)\n",
    "\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('F1 score: {0:0.2f}'.format(f1))\n",
    "print('Accuracy score: {0:0.2f}'.format(acc))\n",
    "print(classification_report(y_test, p_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
