{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP583 - Data Camp\n",
    "# Course project\n",
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have chosen this dataset from Kaggle (https://www.kaggle.com/mlg-ulb/creditcardfraud/data), containing credid card transactions data, and the objective is to predict the transactions which are frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if there is null data\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing 'Time' column and normalizing (scaling) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is necessary, because of the way the SVDD library is coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_svm = labels.copy()\n",
    "labels_svm[labels == 1] = -1 # fraud\n",
    "labels_svm[labels == 0] = 1 # non-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_features = StandardScaler().fit_transform(data.values)\n",
    "scaled_data = pd.DataFrame(scaled_features,\n",
    "                           index=data.index,\n",
    "                           columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.157366e-16</td>\n",
       "      <td>3.154853e-17</td>\n",
       "      <td>-4.409878e-15</td>\n",
       "      <td>-6.734811e-16</td>\n",
       "      <td>-2.874435e-16</td>\n",
       "      <td>4.168992e-16</td>\n",
       "      <td>-8.767997e-16</td>\n",
       "      <td>-2.423604e-16</td>\n",
       "      <td>3.078727e-16</td>\n",
       "      <td>2.026926e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.754870e-16</td>\n",
       "      <td>1.685077e-17</td>\n",
       "      <td>1.478472e-15</td>\n",
       "      <td>-6.797197e-16</td>\n",
       "      <td>1.234659e-16</td>\n",
       "      <td>-7.659279e-16</td>\n",
       "      <td>3.247603e-16</td>\n",
       "      <td>-2.953495e-18</td>\n",
       "      <td>5.401572e-17</td>\n",
       "      <td>3.202236e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "      <td>1.000002e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.879855e+01</td>\n",
       "      <td>-4.403529e+01</td>\n",
       "      <td>-3.187173e+01</td>\n",
       "      <td>-4.013919e+00</td>\n",
       "      <td>-8.240810e+01</td>\n",
       "      <td>-1.963606e+01</td>\n",
       "      <td>-3.520940e+01</td>\n",
       "      <td>-6.130252e+01</td>\n",
       "      <td>-1.222802e+01</td>\n",
       "      <td>-2.258191e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.069146e+01</td>\n",
       "      <td>-4.741907e+01</td>\n",
       "      <td>-1.506565e+01</td>\n",
       "      <td>-7.175446e+01</td>\n",
       "      <td>-4.683638e+00</td>\n",
       "      <td>-1.975033e+01</td>\n",
       "      <td>-5.401098e+00</td>\n",
       "      <td>-5.590660e+01</td>\n",
       "      <td>-4.674612e+01</td>\n",
       "      <td>-3.532294e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.698918e-01</td>\n",
       "      <td>-3.624707e-01</td>\n",
       "      <td>-5.872142e-01</td>\n",
       "      <td>-5.993788e-01</td>\n",
       "      <td>-5.010686e-01</td>\n",
       "      <td>-5.766822e-01</td>\n",
       "      <td>-4.478860e-01</td>\n",
       "      <td>-1.746805e-01</td>\n",
       "      <td>-5.853631e-01</td>\n",
       "      <td>-4.917360e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.746334e-01</td>\n",
       "      <td>-3.109433e-01</td>\n",
       "      <td>-7.473476e-01</td>\n",
       "      <td>-2.591784e-01</td>\n",
       "      <td>-5.854676e-01</td>\n",
       "      <td>-6.084001e-01</td>\n",
       "      <td>-6.780717e-01</td>\n",
       "      <td>-1.755053e-01</td>\n",
       "      <td>-1.604440e-01</td>\n",
       "      <td>-3.308401e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.245351e-03</td>\n",
       "      <td>3.965683e-02</td>\n",
       "      <td>1.186124e-01</td>\n",
       "      <td>-1.401724e-02</td>\n",
       "      <td>-3.936682e-02</td>\n",
       "      <td>-2.058046e-01</td>\n",
       "      <td>3.241723e-02</td>\n",
       "      <td>1.871982e-02</td>\n",
       "      <td>-4.681169e-02</td>\n",
       "      <td>-8.533551e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.104705e-02</td>\n",
       "      <td>-4.009429e-02</td>\n",
       "      <td>9.345377e-03</td>\n",
       "      <td>-1.792420e-02</td>\n",
       "      <td>6.765678e-02</td>\n",
       "      <td>3.183240e-02</td>\n",
       "      <td>-1.081217e-01</td>\n",
       "      <td>3.325174e-03</td>\n",
       "      <td>3.406368e-02</td>\n",
       "      <td>-2.652715e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.716939e-01</td>\n",
       "      <td>4.867202e-01</td>\n",
       "      <td>6.774569e-01</td>\n",
       "      <td>5.250082e-01</td>\n",
       "      <td>4.433465e-01</td>\n",
       "      <td>2.991625e-01</td>\n",
       "      <td>4.611107e-01</td>\n",
       "      <td>2.740785e-01</td>\n",
       "      <td>5.435305e-01</td>\n",
       "      <td>4.168842e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.725733e-01</td>\n",
       "      <td>2.537392e-01</td>\n",
       "      <td>7.283360e-01</td>\n",
       "      <td>2.364319e-01</td>\n",
       "      <td>7.257153e-01</td>\n",
       "      <td>6.728006e-01</td>\n",
       "      <td>4.996663e-01</td>\n",
       "      <td>2.255648e-01</td>\n",
       "      <td>2.371526e-01</td>\n",
       "      <td>-4.471707e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.253351e+00</td>\n",
       "      <td>1.335775e+01</td>\n",
       "      <td>6.187993e+00</td>\n",
       "      <td>1.191874e+01</td>\n",
       "      <td>2.521413e+01</td>\n",
       "      <td>5.502015e+01</td>\n",
       "      <td>9.747824e+01</td>\n",
       "      <td>1.675153e+01</td>\n",
       "      <td>1.419494e+01</td>\n",
       "      <td>2.180758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.113464e+01</td>\n",
       "      <td>3.703471e+01</td>\n",
       "      <td>1.447304e+01</td>\n",
       "      <td>3.607668e+01</td>\n",
       "      <td>7.569684e+00</td>\n",
       "      <td>1.442532e+01</td>\n",
       "      <td>7.293975e+00</td>\n",
       "      <td>7.831940e+01</td>\n",
       "      <td>1.025434e+02</td>\n",
       "      <td>1.023622e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -8.157366e-16  3.154853e-17 -4.409878e-15 -6.734811e-16 -2.874435e-16   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -2.879855e+01 -4.403529e+01 -3.187173e+01 -4.013919e+00 -8.240810e+01   \n",
       "25%   -4.698918e-01 -3.624707e-01 -5.872142e-01 -5.993788e-01 -5.010686e-01   \n",
       "50%    9.245351e-03  3.965683e-02  1.186124e-01 -1.401724e-02 -3.936682e-02   \n",
       "75%    6.716939e-01  4.867202e-01  6.774569e-01  5.250082e-01  4.433465e-01   \n",
       "max    1.253351e+00  1.335775e+01  6.187993e+00  1.191874e+01  2.521413e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.168992e-16 -8.767997e-16 -2.423604e-16  3.078727e-16  2.026926e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -1.963606e+01 -3.520940e+01 -6.130252e+01 -1.222802e+01 -2.258191e+01   \n",
       "25%   -5.766822e-01 -4.478860e-01 -1.746805e-01 -5.853631e-01 -4.917360e-01   \n",
       "50%   -2.058046e-01  3.241723e-02  1.871982e-02 -4.681169e-02 -8.533551e-02   \n",
       "75%    2.991625e-01  4.611107e-01  2.740785e-01  5.435305e-01  4.168842e-01   \n",
       "max    5.502015e+01  9.747824e+01  1.675153e+01  1.419494e+01  2.180758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...       2.754870e-16  1.685077e-17  1.478472e-15 -6.797197e-16   \n",
       "std        ...       1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min        ...      -7.069146e+01 -4.741907e+01 -1.506565e+01 -7.175446e+01   \n",
       "25%        ...      -2.746334e-01 -3.109433e-01 -7.473476e-01 -2.591784e-01   \n",
       "50%        ...      -8.104705e-02 -4.009429e-02  9.345377e-03 -1.792420e-02   \n",
       "75%        ...       1.725733e-01  2.537392e-01  7.283360e-01  2.364319e-01   \n",
       "max        ...       5.113464e+01  3.703471e+01  1.447304e+01  3.607668e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.234659e-16 -7.659279e-16  3.247603e-16 -2.953495e-18  5.401572e-17   \n",
       "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
       "min   -4.683638e+00 -1.975033e+01 -5.401098e+00 -5.590660e+01 -4.674612e+01   \n",
       "25%   -5.854676e-01 -6.084001e-01 -6.780717e-01 -1.755053e-01 -1.604440e-01   \n",
       "50%    6.765678e-02  3.183240e-02 -1.081217e-01  3.325174e-03  3.406368e-02   \n",
       "75%    7.257153e-01  6.728006e-01  4.996663e-01  2.255648e-01  2.371526e-01   \n",
       "max    7.569684e+00  1.442532e+01  7.293975e+00  7.831940e+01  1.025434e+02   \n",
       "\n",
       "             Amount  \n",
       "count  2.848070e+05  \n",
       "mean   3.202236e-16  \n",
       "std    1.000002e+00  \n",
       "min   -3.532294e-01  \n",
       "25%   -3.308401e-01  \n",
       "50%   -2.652715e-01  \n",
       "75%   -4.471707e-02  \n",
       "max    1.023622e+02  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.drop(['Class'], axis=1, inplace=True)\n",
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    284315\n",
      "-1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_counts = labels_svm.value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "# Plot a histogram\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title(\"Fraud distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency (log)\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 99.827%\n"
     ]
    }
   ],
   "source": [
    "print('Baseline: {:.3f}%'.format(len(labels_svm[labels_svm == 1]) / len(labels_svm) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy is therefore 99.827%, so any model which performs below this threshold isn't doing very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2  # \"Pareto rule\", 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data,\n",
    "                                                    labels_svm,\n",
    "                                                    test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will use only non-fraud points to train SVDD\n",
    "In the library we only have SVDD implemented. There is not an implementation of SVDD-neg (a version that incorporates negative examples also)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBSVM:\n",
    "\n",
    "https://github.com/cjlin1/libsvm\n",
    "\n",
    "https://github.com/cjlin1/libsvm/tree/master/python # bindings em Python\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf # article\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf # guide\n",
    "\n",
    "SVDD:\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/#libsvm_for_svdd_and_finding_the_smallest_sphere_containing_all_data\n",
    "\n",
    "One-class SVM:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras pessoas tiveram a mesma pergunta, mas aparentemente ninguÃ©m tem o SVDD-neg implementado\n",
    "https://www.reddit.com/r/MachineLearning/comments/396o0n/experience_training_support_vector_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteca em MATLAB (tem a ver com o criador de SVDD)\n",
    "\n",
    "https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/pattern-recognition-bioinformatics/pattern-recognition-laboratory/data-and-software/dd-tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_fraud_X_train = X_train[y_train==1].values.tolist()\n",
    "non_fraud_y_train = y_train[y_train==1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from svm import *\n",
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem = svm_problem(non_fraud_y_train,\n",
    "                      non_fraud_X_train,\n",
    "                      isKernel=False) # set to True if precomputed Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'C': 6.325283529810813e-06, 'kernel': {'coef0': 1.9690049850021658, 'gamma': 0.9417836463715797, 'type': 3}}\n",
    "param = svm_parameter()\n",
    "param.svm_type = 5\n",
    "param.kernel_type = 3\n",
    "param.degree = 2\n",
    "param.gamma = 0.9417836463715797\n",
    "param.C = 6.325283529810813e-06\n",
    "param.coef0 = 1.9690049850021658\n",
    "param.eps = 0.001\n",
    "param.cross_validation = False\n",
    "param.nr_fold = 0\n",
    "model = svm_train(problem, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.values.tolist()\n",
    "X_test = X_test.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we don't use the negative labels in the training set, I am adding them to our test set (maybe this is wrong to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test.extend(y_train[y_train==-1].values.tolist())\n",
    "X_test.extend(X_train[y_train==-1].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.1422% (56862/57354) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99.14216968302124, 0.03431321267915054, 0.0009902167601729527)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = np.array(p_val)\n",
    "lab = np.array(p_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = val.reshape(val.shape[0])\n",
    "lab = lab.reshape(lab.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(np.where(lab<0)).flatten() == np.array(np.where(val>0)).flatten()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_label : +1 para nÃ£o fraude, -1 para fraude\n",
    "\n",
    "p_val : negativo para nÃ£o fraude, positivo para fraude (nÃ£o sei nada sobre a magnitude de p_val ainda, mas acredito que seja a distÃ¢ncia atÃ© a decision boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under the precision-recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVDD method doesn't predict probabilities, but the output p_val is the distance of each point to the decision boundary (negative for non-frauds and positive for frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'2-class Precision-Recall curve: AP=0.015')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, p_val, pos_label=-1)\n",
    "average_precision = -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.3f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014140976905742609"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "\n",
    "auc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Objective_SVDD(object):\n",
    "    \"\"\"\n",
    "    A class to encapsulate the SVC model and our objective function (the error in this case, to minimize)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.history_f = []\n",
    "        self.fbest = np.inf\n",
    "        self.history_f_best = []\n",
    "        self.problem = svm_problem(non_fraud_y_train,\n",
    "                                   non_fraud_X_train,\n",
    "                                   isKernel=False) # set to True if precomputed Kernel\n",
    "        \n",
    "    def encode(self, C, gamma):\n",
    "        \"\"\"\n",
    "        Returns a dict with the square value of the arguments C and gamma.\n",
    "        \"\"\"\n",
    "        return {'C': C ** 2, 'gamma': gamma ** 2}\n",
    "    \n",
    "    def __call__(self, pair):\n",
    "        params = self.encode(*pair)\n",
    "        C_in = params['C']\n",
    "        gamma_in = params['gamma']\n",
    "        \n",
    "        param = svm_parameter()\n",
    "        param.svm_type = 5\n",
    "        param.kernel_type = 2\n",
    "        param.degree = 2\n",
    "        param.gamma = gamma_in\n",
    "        param.C = C_in\n",
    "        param.eps = 0.001\n",
    "        param.cross_validation = False\n",
    "        param.nr_fold = 0\n",
    "        \n",
    "        model = svm_train(self.problem, param)\n",
    "\n",
    "        p_label, p_acc, p_val = svm_predict(y_test, X_test, model)\n",
    "        \n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, p_val, pos_label=-1)\n",
    "        average_precision = -np.sum(np.diff(recall) * np.array(precision)[:-1])\n",
    "        \n",
    "        f = 1 - average_precision # error function\n",
    "        \n",
    "        self.history_f.append(f)\n",
    "        if f < self.fbest:\n",
    "            self.fbest = f\n",
    "        self.history_f_best.append(self.fbest)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=222371, Wed Mar 14 23:47:53 2018)\n",
      "Accuracy = 5.22893% (2999/57354) (classification)\n",
      "Accuracy = 0.861317% (494/57354) (classification)\n",
      "Accuracy = 0.871779% (500/57354) (classification)\n",
      "Accuracy = 0.868292% (498/57354) (classification)\n",
      "Accuracy = 0.915368% (525/57354) (classification)\n",
      "Accuracy = 0.866548% (497/57354) (classification)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      6 4.655806334020522e-01 1.0e+00 2.30e-01  2e-01  2e-01 5:15.7\n",
      "Accuracy = 96.1101% (55123/57354) (classification)\n",
      "Accuracy = 99.388% (57003/57354) (classification)\n",
      "Accuracy = 97.2382% (55770/57354) (classification)\n",
      "Accuracy = 0.870035% (499/57354) (classification)\n",
      "Accuracy = 98.8894% (56717/57354) (classification)\n",
      "Accuracy = 0.868292% (498/57354) (classification)\n",
      "    2     12 3.960411604462672e-01 1.3e+00 3.10e-01  2e-01  4e-01 8:26.3\n",
      "Accuracy = 99.2694% (56935/57354) (classification)\n",
      "Accuracy = 99.2834% (56943/57354) (classification)\n",
      "Accuracy = 0.873522% (501/57354) (classification)\n",
      "Accuracy = 99.2764% (56939/57354) (classification)\n",
      "Accuracy = 0.918855% (527/57354) (classification)\n",
      "Accuracy = 4.00321% (2296/57354) (classification)\n",
      "    3     18 4.635287896105000e-01 1.7e+00 2.71e-01  2e-01  3e-01 10:50.4\n",
      "Accuracy = 16.1401% (9257/57354) (classification)\n",
      "Accuracy = 15.3625% (8811/57354) (classification)\n",
      "Accuracy = 86.5275% (49627/57354) (classification)\n",
      "Accuracy = 1.17167% (672/57354) (classification)\n",
      "Accuracy = 99.4595% (57044/57354) (classification)\n",
      "Accuracy = 96.3821% (55279/57354) (classification)\n",
      "    4     24 4.166923672268338e-01 1.9e+00 3.34e-01  3e-01  4e-01 81:33.7\n",
      "Accuracy = 0.863061% (495/57354) (classification)\n",
      "Accuracy = 1.08624% (623/57354) (classification)\n",
      "Accuracy = 17.6396% (10117/57354) (classification)\n",
      "Accuracy = 40.386% (23163/57354) (classification)\n",
      "Accuracy = 1.03742% (595/57354) (classification)\n",
      "Accuracy = 18.1243% (10395/57354) (classification)\n",
      "    5     30 4.461960844110630e-01 2.3e+00 2.60e-01  2e-01  3e-01 86:46.8\n",
      "Accuracy = 97.9932% (56203/57354) (classification)\n",
      "Accuracy = 1.44715% (830/57354) (classification)\n",
      "Accuracy = 46.3002% (26555/57354) (classification)\n",
      "Accuracy = 99.2851% (56944/57354) (classification)\n",
      "Accuracy = 0.896189% (514/57354) (classification)\n",
      "Accuracy = 1.7174% (985/57354) (classification)\n",
      "    6     36 4.174466245027894e-01 2.0e+00 3.31e-01  3e-01  3e-01 90:56.3\n",
      "Accuracy = 99.4299% (57027/57354) (classification)\n",
      "Accuracy = 99.4142% (57018/57354) (classification)\n",
      "Accuracy = 49.4089% (28338/57354) (classification)\n",
      "Accuracy = 99.3601% (56987/57354) (classification)\n",
      "Accuracy = 0.868292% (498/57354) (classification)\n",
      "Accuracy = 0.873522% (501/57354) (classification)\n",
      "    7     42 3.868251604138052e-01 1.5e+00 4.41e-01  4e-01  5e-01 94:26.1\n",
      "Accuracy = 0.93106% (534/57354) (classification)\n",
      "Accuracy = 25.3165% (14520/57354) (classification)\n",
      "Accuracy = 72.6209% (41651/57354) (classification)\n",
      "Accuracy = 98.5075% (56498/57354) (classification)\n",
      "Accuracy = 1.41751% (813/57354) (classification)\n",
      "Accuracy = 0.861317% (494/57354) (classification)\n",
      "    8     48 4.162428544357011e-01 2.0e+00 4.49e-01  4e-01  5e-01 99:43.1\n",
      "Accuracy = 0.861317% (494/57354) (classification)\n",
      "Accuracy = 99.0794% (56826/57354) (classification)\n",
      "Accuracy = 97.8816% (56139/57354) (classification)\n",
      "Accuracy = 1.19434% (685/57354) (classification)\n",
      "Accuracy = 8.90784% (5109/57354) (classification)\n",
      "Accuracy = 0.894445% (513/57354) (classification)\n",
      "    9     54 4.168297464679126e-01 1.9e+00 4.50e-01  3e-01  5e-01 103:46.9\n",
      "Accuracy = 0.877009% (503/57354) (classification)\n",
      "Accuracy = 7.01259% (4022/57354) (classification)\n",
      "Accuracy = 96.3717% (55273/57354) (classification)\n",
      "Accuracy = 99.198% (56894/57354) (classification)\n",
      "Accuracy = 99.1509% (56867/57354) (classification)\n",
      "Accuracy = 99.2817% (56942/57354) (classification)\n",
      "   10     60 4.173506337473774e-01 1.9e+00 3.66e-01  2e-01  3e-01 106:49.2\n",
      "Accuracy = 99.4229% (57023/57354) (classification)\n",
      "Accuracy = 99.3584% (56986/57354) (classification)\n"
     ]
    }
   ],
   "source": [
    "fun_cma = Objective_SVDD()\n",
    "res_cma = cma.fmin(fun_cma, np.array([0.5, 0.5]), 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cma.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy: {}\".format(1 - res_cma[1]))\n",
    "print(\"Optimal parameters: {}\".format(fun_cma.encode(*res_cma[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimized_params = fun_cma.encode(*res_cma[0])\n",
    "param.C = optimized_params['C']\n",
    "param.gamma = optimized_params['gamma']\n",
    "model = svm_train(problem, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_save_model('./model_1.m', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm_load_model('./model_1.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_label, p_acc, p_val = svm_predict(y_test, X_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (average_precision_score,\n",
    "                             accuracy_score,\n",
    "                             classification_report,\n",
    "                             f1_score)\n",
    "average_precision = average_precision_score(y_test, p_val)\n",
    "f1 = f1_score(y_test, p_label)\n",
    "acc = accuracy_score(y_test, p_label)\n",
    "\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "print('F1 score: {0:0.2f}'.format(f1))\n",
    "print('Accuracy score: {0:0.2f}'.format(acc))\n",
    "print(classification_report(y_test, p_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
